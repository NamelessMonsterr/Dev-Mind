# DevMind: Product Requirements Document (PRD)

**Version:** 1.0  
**Date:** 2026-02-07  
**Status:** Draft â†’ Ready for Development  
**Owner:** DevMind Core Team

---

## 1. Executive Summary

### Vision

DevMind is a **production-grade AI development assistant** that transforms how developers interact with code, documentation, and knowledge bases through advanced Retrieval-Augmented Generation (RAG) technology.

### Problem Statement

Current challenges in software development:

- **Context Fragmentation**: Code, docs, architecture decisions scattered across repos, wikis, and chat
- **Knowledge Silos**: Tribal knowledge locked in team members' heads, not searchable
- **Inefficient Search**: Keyword-based search fails for semantic queries ("How do we handle authentication?")
- **Slow Onboarding**: New developers spend weeks understanding legacy codebases
- **Code Discovery**: Developers reinvent solutions instead of finding existing implementations

### Solution

DevMind provides **intelligent, context-aware assistance** by:

1. **Understanding** your entire codebase semantically (not just keywords)
2. **Retrieving** relevant code, docs, and context using hybrid search
3. **Generating** accurate, grounded responses with citations
4. **Learning** from your project structure and conventions

### Success Metrics

| Metric                 | Target    | Measurement                     |
| ---------------------- | --------- | ------------------------------- |
| Query Response Time    | <2s (p95) | API latency monitoring          |
| Retrieval Accuracy     | >80%      | Human eval on test set          |
| Developer Productivity | +30%      | Time-to-solution surveys        |
| Onboarding Time        | -50%      | New hire surveys                |
| Code Reuse             | +40%      | Discovery vs. reinvention ratio |

---

## 2. User Personas

### Primary: Backend Developer (Maya)

- **Role**: Senior Backend Engineer at mid-size SaaS company
- **Pain**: Wastes 2-3 hours/day searching for "how we did X before"
- **Goal**: Find relevant code examples and understand system architecture quickly
- **Technical Level**: High (comfortable with APIs, CLI tools)

### Secondary: Frontend Developer (Alex)

- **Role**: Mid-level React Developer
- **Pain**: Struggles to understand backend APIs and data flows
- **Goal**: Discover API endpoints, understand request/response formats
- **Technical Level**: Medium (prefers GUI, occasional CLI)

### Tertiary: Tech Lead / Architect (Jordan)

- **Role**: Engineering Manager / Tech Lead
- **Pain**: Explaining architecture decisions to new hires repeatedly
- **Goal**: Create searchable knowledge base of architectural decisions
- **Technical Level**: Very High (infrastructure, DevOps)

---

## 3. Core Features (MVP)

### 3.1 Intelligent Code Search

**User Story:**

> As a developer, I want to ask natural language questions about my codebase and get accurate code snippets with context, so I can find solutions faster.

**Functional Requirements:**

- **FR-1.1**: Accept natural language queries (e.g., "How do we authenticate API requests?")
- **FR-1.2**: Return top 5-10 relevant code snippets with file paths and line numbers
- **FR-1.3**: Highlight relevant portions of code (not entire files)
- **FR-1.4**: Support semantic search (understand intent, not just keywords)
- **FR-1.5**: Filter results by file type, directory, date modified

**Non-Functional Requirements:**

- **NFR-1.1**: Response time <2s for 95% of queries
- **NFR-1.2**: Support codebases up to 1M lines of code
- **NFR-1.3**: Handle concurrent queries from 100+ users

**Acceptance Criteria:**

```gherkin
Given a codebase with authentication logic in auth/jwt.py
When I query "How do we verify JWT tokens?"
Then I should receive:
  - Code snippet from auth/jwt.py (verify_token function)
  - File path and line numbers
  - Related snippets (e.g., token generation, middleware)
  - Response time <2s
```

---

### 3.2 Multi-Format Document Ingestion

**User Story:**

> As a tech lead, I want to index code, markdown docs, and PDFs so the entire knowledge base is searchable in one place.

**Functional Requirements:**

- **FR-2.1**: Index source code (.py, .js, .ts, .java, .go, .cpp, .rs)
- **FR-2.2**: Index documentation (.md, .rst, .txt)
- **FR-2.3**: Index design docs (.pdf, .docx)
- **FR-2.4**: Extract metadata (author, date, git commit)
- **FR-2.5**: Incremental updates (detect and reindex changed files only)
- **FR-2.6**: Progress tracking during indexing

**Non-Functional Requirements:**

- **NFR-2.1**: Index 10K files in <10 minutes
- **NFR-2.2**: Support repos up to 10GB
- **NFR-2.3**: Graceful handling of binary files (skip)

**Acceptance Criteria:**

```gherkin
Given a repo with 5K Python files and 200 Markdown docs
When I trigger indexing
Then:
  - All files are processed in <5 minutes
  - Progress bar shows % complete
  - Errors logged but don't halt indexing
  - Vector embeddings stored in Qdrant
```

---

### 3.3 Context-Aware Responses

**User Story:**

> As a developer, I want to receive not just code snippets but explanations with context, so I understand how the code fits into the system.

**Functional Requirements:**

- **FR-3.1**: Generate explanations using LLM (GPT-4, Claude, Gemini)
- **FR-3.2**: Include citations (file paths, line numbers)
- **FR-3.3**: Provide related code (dependencies, callers)
- **FR-3.4**: Stream responses for better UX
- **FR-3.5**: Allow follow-up questions (conversational mode)

**Non-Functional Requirements:**

- **NFR-3.1**: First token in <500ms
- **NFR-3.2**: Hallucination rate <5% (grounded in retrieved context)
- **NFR-3.3**: Support multi-turn conversations (up to 10 messages)

**Acceptance Criteria:**

```gherkin
Given I asked "How does authentication work?"
When I receive the response
Then:
  - Explanation is generated based on retrieved code
  - Citations include file:line references
  - Response streams incrementally
  - I can ask "What about authorization?" as follow-up
```

---

### 3.4 API & CLI Interfaces

**User Story:**

> As a developer, I want to access DevMind via API and CLI so I can integrate it into my workflow (IDE, CI/CD, scripts).

**Functional Requirements:**

- **FR-4.1**: RESTful API with OpenAPI spec
- **FR-4.2**: CLI tool (`devmind ask "query"`)
- **FR-4.3**: API authentication (API keys, JWT)
- **FR-4.4**: Rate limiting (100 req/min per user)
- **FR-4.5**: Query history and analytics

**API Endpoints:**

```
POST /query              # Submit query, get response
GET  /query/{id}         # Poll query status (async mode)
POST /index              # Trigger indexing
GET  /index/status       # Get indexing progress
POST /documents          # Upload documents
DELETE /index            # Clear index
GET  /health             # Health check
```

**CLI Commands:**

```bash
devmind ask "query"               # Interactive query
devmind index /path/to/repo       # Index repository
devmind status                    # Show index status
devmind config set api_key=xxx    # Configure
```

**Acceptance Criteria:**

```gherkin
Given I have an API key
When I run: curl -H "Authorization: Bearer $KEY" -d '{"query":"..."}' POST /query
Then:
  - I receive a 200 response with results
  - Response includes query_id, results[], citations[]
  - Request is rate-limited after 100 calls
```

---

## 4. Technical Architecture (High-Level)

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Clients   â”‚  (Web UI, CLI, IDE Plugins)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI    â”‚  (API Gateway, Auth, Rate Limiting)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAG Pipeline                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Query  â”‚â†’ â”‚Retrieveâ”‚â†’        â”‚
â”‚  â”‚Process â”‚  â”‚        â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜         â”‚
â”‚                   â”‚              â”‚
â”‚              â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”         â”‚
â”‚              â”‚ Rerank  â”‚         â”‚
â”‚              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â”‚
â”‚                   â”‚              â”‚
â”‚              â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”         â”‚
â”‚              â”‚Generate â”‚         â”‚
â”‚              â”‚  (LLM)  â”‚         â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   Qdrant    â”‚    â”‚ PostgreSQL  â”‚
â”‚ (Vectors)   â”‚    â”‚  (Metadata) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

| Layer          | Technology            | Justification                     |
| -------------- | --------------------- | --------------------------------- |
| **API**        | FastAPI               | High performance, async, OpenAPI  |
| **Vector DB**  | Qdrant                | Self-hostable, fast, good docs    |
| **Embeddings** | sentence-transformers | Open-source, quality embeddings   |
| **Database**   | PostgreSQL            | Robust, ACID, JSON support        |
| **Cache**      | Redis                 | Fast, widely supported            |
| **LLM**        | Multi-provider        | OpenAI, Anthropic, Gemini, Ollama |
| **Deployment** | Docker Compose        | Easy local dev, scalable          |

---

## 5. Advanced Features (Post-MVP)

### 5.1 Agentic Code Assistant (Phase 2)

- Multi-step reasoning: "Find all API endpoints that modify user data, check if they have authentication, and suggest improvements"
- Tool use: Execute code, run tests, generate patches

### 5.2 Team Collaboration (Phase 2)

- Shared knowledge bases
- Team-specific context (coding standards, architecture decisions)
- Query analytics (what does the team ask most?)

### 5.3 IDE Plugins (Phase 3)

- VSCode extension
- IntelliJ IDEA plugin
- Inline suggestions based on context

### 5.4 CI/CD Integration (Phase 3)

- Pre-commit checks: "Does this code follow our patterns?"
- PR reviews: "Summarize changes and suggest improvements"
- Automated documentation updates

---

## 6. User Experience (UX)

### 6.1 Web UI (MVP)

**Home Page:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DevMind                         [âš™ï¸]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                        â”‚
â”‚  ğŸ”  Ask anything about your code...   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ How do we handle authentication? â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           [Search] ğŸ”  â”‚
â”‚                                        â”‚
â”‚  Recent Queries:                       â”‚
â”‚  â€¢ How to add a new API endpoint       â”‚
â”‚  â€¢ Database migration process          â”‚
â”‚  â€¢ Error handling patterns             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Results Page:**

````
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query: "How do we handle auth?"       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ’¡ Answer:                            â”‚
â”‚  Authentication is handled via JWT...  â”‚
â”‚                                        â”‚
â”‚  ğŸ“ Citations:                         â”‚
â”‚  1. auth/jwt.py:45-67                  â”‚
â”‚     ```python                          â”‚
â”‚     def verify_token(token):           â”‚
â”‚         ...                            â”‚
â”‚     ```                                â”‚
â”‚     [View full file] [Copy code]       â”‚
â”‚                                        â”‚
â”‚  2. middleware/auth.py:12-34           â”‚
â”‚     ...                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
````

### 6.2 CLI Experience

```bash
$ devmind ask "How do we handle database migrations?"

ğŸ” Searching codebase...

ğŸ’¡ Answer:
Database migrations are managed using Alembic. The process is:
1. Create migration: `alembic revision -m "description"`
2. Edit migration in migrations/versions/
3. Apply: `alembic upgrade head`

ğŸ“ Citations:
â€¢ migrations/env.py:23-45
â€¢ alembic.ini:1-20
â€¢ scripts/migrate.sh:5-12

Need more details? Ask a follow-up question or run:
  devmind ask "Show me an example migration"
```

---

## 7. Data & Privacy

### 7.1 Data Storage

- **Code & Docs**: Stored as embeddings in Qdrant (vector representations)
- **Metadata**: File paths, timestamps in PostgreSQL
- **Queries**: Logged for analytics (anonymized option available)
- **Conversations**: Stored temporarily (configurable retention)

### 7.2 Privacy & Security

- **Self-Hosted**: All data stays on your infrastructure
- **No External Calls**: Code never leaves your network (except LLM API calls)
- **LLM Options**: Support for local LLMs (Ollama) for airgapped environments
- **Access Control**: Role-based access (admin, user, readonly)
- **Audit Logs**: Track all queries and access

---

## 8. Performance Requirements

| Metric                 | Requirement               | Measurement Method           |
| ---------------------- | ------------------------- | ---------------------------- |
| **Query Latency**      | <2s (p95), <5s (p99)      | API response time monitoring |
| **Indexing Speed**     | 10K files in <10 min      | Timed batch jobs             |
| **Concurrent Users**   | 100+ simultaneous queries | Load testing                 |
| **Uptime**             | 99.5%                     | Health checks, alerting      |
| **Retrieval Accuracy** | >80% relevant results     | Human eval on test set       |
| **Embedding Quality**  | Similarity score >0.7     | Benchmark dataset            |

---

## 9. Development Roadmap

### Phase 1: Foundation (Weeks 1-4)

- [x] Architecture design
- [ ] API skeleton + Auth
- [ ] Database models
- [ ] Vector store integration
- [ ] Basic embedding service

### Phase 2: Core RAG (Weeks 5-8)

- [ ] File ingestion pipeline
- [ ] Semantic search
- [ ] Hybrid retrieval (semantic + keyword)
- [ ] Reranking
- [ ] LLM integration

### Phase 3: Polish (Weeks 9-10)

- [ ] Web UI
- [ ] CLI tool
- [ ] Documentation
- [ ] Testing & benchmarks
- [ ] Deployment guides

### Phase 4: Advanced (Weeks 11-14)

- [ ] Conversational mode
- [ ] GraphRAG integration
- [ ] Advanced chunking strategies
- [ ] Team collaboration features

---

## 10. Success Criteria

### MVP Launch Criteria

- âœ… Index a 10K-file repo in <10 minutes
- âœ… Query response time <2s (p95)
- âœ… Retrieval accuracy >80% on benchmark
- âœ… Support 5 file types (py, js, ts, md, pdf)
- âœ… REST API with auth
- âœ… CLI tool functional
- âœ… Documentation complete
- âœ… Deployed on staging

### Beta Launch Criteria (3 months)

- âœ… 50+ active users
- âœ… 1000+ queries/day
- âœ… <5% error rate
- âœ… User satisfaction >4/5
- âœ… IDE plugin (VSCode)

---

## 11. Risks & Mitigation

| Risk                       | Impact | Probability | Mitigation                                              |
| -------------------------- | ------ | ----------- | ------------------------------------------------------- |
| **Poor retrieval quality** | High   | Medium      | Continuous eval, reranking, query transformation        |
| **Slow indexing**          | Medium | Medium      | Batch processing, incremental updates, parallel workers |
| **LLM API costs**          | High   | High        | Rate limiting, caching, local LLM fallback              |
| **Vector DB scaling**      | Medium | Low         | Sharding strategy, monitoring, collection limits        |
| **Hallucinations**         | High   | Medium      | Grounded generation, citations, fact-checking           |

---

## 12. Open Questions

1. **LLM Provider**: Which primary LLM? (OpenAI GPT-4 vs. Anthropic Claude vs. local Ollama)
2. **Embedding Model**: `all-MiniLM-L6-v2` (fast) vs. `bge-large-en-v1.5` (accurate)?
3. **Chunking Strategy**: Fixed-size vs. semantic vs. code-aware?
4. **Deployment**: Docker Compose vs. Kubernetes?
5. **Pricing Model**: Free tier limits? Usage-based pricing?

---

## 13. Appendix

### A. Competitive Analysis

| Product            | Strengths                        | Weaknesses                     | DevMind Advantage                  |
| ------------------ | -------------------------------- | ------------------------------ | ---------------------------------- |
| **GitHub Copilot** | Code completion, IDE integration | No codebase search, cloud-only | Self-hosted, full codebase context |
| **Sourcegraph**    | Code search, navigation          | Keyword-based, expensive       | Semantic search, RAG-powered       |
| **Codeium**        | Free, fast                       | Limited context, cloud-only    | Enterprise self-hosting            |
| **Cursor**         | AI editor                        | Not a search tool              | Complementary (can integrate)      |

### B. User Feedback (From Persona Interviews)

> "I spend 30% of my day searching for code examples. If DevMind can cut that to 10%, that's a game-changer." - Maya, Backend Dev

> "I wish I could just ask 'Where's the user service?' instead of grepping for 20 minutes." - Alex, Frontend Dev

> "We need a searchable knowledge base for architecture decisions. This would save hours in onboarding." - Jordan, Tech Lead

---

---

## 14. Technical Decisions (FINALIZED)

> **Status**: âœ… Decisions Approved  
> **Date**: 2026-02-07  
> **Authority**: Architecture Team + Environment Analysis

### Decision 1: LLM Provider

| Phase                  | LLM                             | Justification                                                                              |
| ---------------------- | ------------------------------- | ------------------------------------------------------------------------------------------ |
| **MVP / Local Dev**    | **Ollama + Phi-3**              | Free, fast on CPU/GPU, private, ideal for ingestion pipeline, good for chunk summarization |
| **Production**         | **Anthropic Claude 4.5 Sonnet** | Best reasoning for code, superior multi-hop logic, lower hallucination rate                |
| **Advanced Reasoning** | **Claude 4.5 Opus (Thinking)**  | Architectural evaluation, complex cross-source reasoning, multi-hop semantic fusion        |

**Rationale:**

- Phi-3 is NOT strong enough for deep code reasoning but perfect for early infrastructure build
- Claude 4.5 Sonnet > GPT-4o for code understanding and reasoning
- Multi-provider support allows gradual migration from local â†’ cloud

### Decision 2: Embedding Models

| Purpose               | Model               | Dimensions | Justification                                                       |
| --------------------- | ------------------- | ---------- | ------------------------------------------------------------------- |
| **MVP**               | `all-MiniLM-L6-v2`  | 384        | Fast, runs locally, good for pipeline validation                    |
| **Production (Docs)** | `bge-large-en-v1.5` | 1024       | Best RAG performance, high recall                                   |
| **Production (Code)** | `bge-code-large`    | 1024       | Code-specific training, superior semantic alignment for code search |

**Migration Path:**

1. Start with MiniLM (Week 1-2)
2. Migrate to BGE-Large for docs (Week 5)
3. Add BGE-Code for code index (Week 7)

### Decision 3: First Component to Build

**âœ… Embedding Service** (Critical Path)

**Why Embedding Service First:**

- Everything depends on embeddings (retrieval, API, ingestion)
- Can validate architecture early
- Unblocks all downstream work
- Testable without frontend

**Build Order:**

1. Embedding Service (Week 1-2) â† **START HERE**
2. File Ingestion (Week 3-4)
3. Retrieval Engine (Week 5-6)
4. API Layer (Week 7-8)
5. Generation + UI (Week 9-10)

**NOT Building First:**

- âŒ API Layer (useless without embeddings)
- âŒ UI (no backend yet)
- âŒ Vertical Slice (too complex for first step)

---

**Next Steps:**

1. âœ… Review and approve PRD
2. âœ… Finalize technical decisions (LLM, embeddings, chunking)
3. âœ… Create implementation plan matching architecture blueprint
4. ğŸš€ **Start development: Build Embedding Service** (See [embedding-service-implementation.md](file:///C:/Users/91701/.gemini/antigravity/brain/c6bc788c-c94b-41a1-a2f0-796f11dc2cf0/embedding-service-implementation.md))

---

**Document Status:** âœ… Approved & Ready for Development  
**Last Updated:** 2026-02-07  
**Contributors:** DevMind Architecture Team
